{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02. Predict Employee Attrition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: failed with initial frozen solve. Retrying with flexible solve.\n",
      "Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.8.2\n",
      "  latest version: 4.8.3\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /opt/anaconda3/envs/hr\n",
      "\n",
      "  added / updated specs:\n",
      "    - pandas\n",
      "    - tensorflow\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    pandas-1.0.4               |   py37h959d312_0         7.9 MB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         7.9 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  _tflow_select      pkgs/main/osx-64::_tflow_select-2.3.0-mkl\n",
      "  absl-py            pkgs/main/osx-64::absl-py-0.9.0-py37_0\n",
      "  astor              pkgs/main/osx-64::astor-0.8.0-py37_0\n",
      "  blas               pkgs/main/osx-64::blas-1.0-mkl\n",
      "  c-ares             pkgs/main/osx-64::c-ares-1.15.0-h1de35cc_1001\n",
      "  gast               pkgs/main/osx-64::gast-0.2.2-py37_0\n",
      "  google-pasta       pkgs/main/noarch::google-pasta-0.2.0-py_0\n",
      "  grpcio             pkgs/main/osx-64::grpcio-1.16.1-py37h044775b_1\n",
      "  h5py               pkgs/main/osx-64::h5py-2.10.0-py37h3134771_0\n",
      "  hdf5               pkgs/main/osx-64::hdf5-1.10.4-hfa1e0ec_0\n",
      "  intel-openmp       pkgs/main/osx-64::intel-openmp-2019.4-233\n",
      "  keras-applications pkgs/main/noarch::keras-applications-1.0.8-py_0\n",
      "  keras-preprocessi~ pkgs/main/noarch::keras-preprocessing-1.1.0-py_1\n",
      "  libgfortran        pkgs/main/osx-64::libgfortran-3.0.1-h93005f0_2\n",
      "  libprotobuf        pkgs/main/osx-64::libprotobuf-3.12.3-hab81aa3_0\n",
      "  markdown           pkgs/main/osx-64::markdown-3.1.1-py37_0\n",
      "  mkl                pkgs/main/osx-64::mkl-2019.4-233\n",
      "  mkl-service        pkgs/main/osx-64::mkl-service-2.3.0-py37hfbe908c_0\n",
      "  mkl_fft            pkgs/main/osx-64::mkl_fft-1.0.15-py37h5e564d8_0\n",
      "  mkl_random         pkgs/main/osx-64::mkl_random-1.1.1-py37h959d312_0\n",
      "  numpy              pkgs/main/osx-64::numpy-1.18.1-py37h7241aed_0\n",
      "  numpy-base         pkgs/main/osx-64::numpy-base-1.18.1-py37h3304bdc_1\n",
      "  opt_einsum         pkgs/main/noarch::opt_einsum-3.1.0-py_0\n",
      "  pandas             pkgs/main/osx-64::pandas-1.0.4-py37h959d312_0\n",
      "  protobuf           pkgs/main/osx-64::protobuf-3.12.3-py37hb1e8313_0\n",
      "  pytz               pkgs/main/noarch::pytz-2020.1-py_0\n",
      "  scipy              pkgs/main/osx-64::scipy-1.4.1-py37h9fa6033_0\n",
      "  tensorboard        pkgs/main/noarch::tensorboard-2.0.0-pyhb38c66f_1\n",
      "  tensorflow         pkgs/main/osx-64::tensorflow-2.0.0-mkl_py37hda344b4_0\n",
      "  tensorflow-base    pkgs/main/osx-64::tensorflow-base-2.0.0-mkl_py37h66b1bf0_0\n",
      "  tensorflow-estima~ pkgs/main/noarch::tensorflow-estimator-2.0.0-pyh2649769_0\n",
      "  termcolor          pkgs/main/osx-64::termcolor-1.1.0-py37_1\n",
      "  werkzeug           pkgs/main/noarch::werkzeug-1.0.1-py_0\n",
      "  wrapt              pkgs/main/osx-64::wrapt-1.12.1-py37h1de35cc_1\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "pandas-1.0.4         | 7.9 MB    | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n"
     ]
    }
   ],
   "source": [
    "#Install all related packages. If you find additional packages missing, please follow the same technique.\n",
    "#If you are not using anaconda, then use pip to install the same packages\n",
    "\n",
    "import sys\n",
    "!conda install --yes --prefix {sys.prefix} pandas tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02.04. Preprocessing Attrition Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Loaded:\n",
      "------------------------\n",
      " EmployeeID              int64\n",
      "TotalMonthsOfExp        int64\n",
      "TotalOrgsWorked         int64\n",
      "MonthsInOrg             int64\n",
      "LastPayIncrementBand    int64\n",
      "AverageFeedback         int64\n",
      "LastPromotionYears      int64\n",
      "Attrition               int64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EmployeeID</th>\n",
       "      <th>TotalMonthsOfExp</th>\n",
       "      <th>TotalOrgsWorked</th>\n",
       "      <th>MonthsInOrg</th>\n",
       "      <th>LastPayIncrementBand</th>\n",
       "      <th>AverageFeedback</th>\n",
       "      <th>LastPromotionYears</th>\n",
       "      <th>Attrition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>110</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>103</td>\n",
       "      <td>3</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>41</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>80</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   EmployeeID  TotalMonthsOfExp  TotalOrgsWorked  MonthsInOrg  \\\n",
       "0           1               110                4            9   \n",
       "1           2               103                3           51   \n",
       "2           3                41                4           16   \n",
       "3           4                32                4           17   \n",
       "4           5                80                3           16   \n",
       "\n",
       "   LastPayIncrementBand  AverageFeedback  LastPromotionYears  Attrition  \n",
       "0                     5                4                   4          1  \n",
       "1                     1                4                   2          0  \n",
       "2                     5                4                   4          1  \n",
       "3                     5                2                   3          0  \n",
       "4                     3                4                   2          0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the dataset and analyze\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "attrition_data = pd.read_csv(\"employee_attrition.csv\")\n",
    "\n",
    "print(\"Data Loaded:\\n------------------------\\n\",attrition_data.dtypes)\n",
    "attrition_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EmployeeID             -0.036630\n",
       "TotalMonthsOfExp        0.019702\n",
       "TotalOrgsWorked         0.008706\n",
       "MonthsInOrg             0.012605\n",
       "LastPayIncrementBand    0.108528\n",
       "AverageFeedback        -0.008253\n",
       "LastPromotionYears      0.765641\n",
       "Attrition               1.000000\n",
       "Name: Attrition, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Correlation Analysis of target attribute\n",
    "\n",
    "attrition_data.corr()['Attrition']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X-Train Shape :  (1000, 6)\n",
      "Y-Train Shape :  (1000, 2)\n"
     ]
    }
   ],
   "source": [
    "#Convert to Dataframe to numpy array\n",
    "np_attrition = attrition_data.to_numpy().astype(float)\n",
    "\n",
    "#Create X_train with the first 7 attributes\n",
    "X_train = np_attrition[:,1:7]\n",
    "#Create Y_train with attrition attribute\n",
    "Y_train=np_attrition[:,7]\n",
    "\n",
    "#Convert Y_train to one-hot-encoding\n",
    "Y_train = tf.keras.utils.to_categorical(Y_train,2)\n",
    "\n",
    "print(\"X-Train Shape : \", X_train.shape)\n",
    "print(\"Y-Train Shape : \", Y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02.05. Build Attrition model with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/100\n",
      "800/800 [==============================] - 1s 1ms/sample - loss: 1.3129 - accuracy: 0.5763 - val_loss: 0.9543 - val_accuracy: 0.7650\n",
      "Epoch 2/100\n",
      "800/800 [==============================] - 0s 135us/sample - loss: 0.7433 - accuracy: 0.7412 - val_loss: 0.8353 - val_accuracy: 0.3600\n",
      "Epoch 3/100\n",
      "800/800 [==============================] - 0s 128us/sample - loss: 0.6763 - accuracy: 0.6750 - val_loss: 0.6184 - val_accuracy: 0.7900\n",
      "Epoch 4/100\n",
      "800/800 [==============================] - 0s 113us/sample - loss: 0.5645 - accuracy: 0.7675 - val_loss: 0.5561 - val_accuracy: 0.7700\n",
      "Epoch 5/100\n",
      "800/800 [==============================] - 0s 133us/sample - loss: 0.5146 - accuracy: 0.7763 - val_loss: 0.5035 - val_accuracy: 0.7700\n",
      "Epoch 6/100\n",
      "800/800 [==============================] - 0s 110us/sample - loss: 0.4811 - accuracy: 0.7825 - val_loss: 0.4723 - val_accuracy: 0.7800\n",
      "Epoch 7/100\n",
      "800/800 [==============================] - 0s 124us/sample - loss: 0.4557 - accuracy: 0.7962 - val_loss: 0.4396 - val_accuracy: 0.7950\n",
      "Epoch 8/100\n",
      "800/800 [==============================] - 0s 127us/sample - loss: 0.4487 - accuracy: 0.8012 - val_loss: 0.4198 - val_accuracy: 0.8200\n",
      "Epoch 9/100\n",
      "800/800 [==============================] - 0s 127us/sample - loss: 0.4293 - accuracy: 0.8062 - val_loss: 0.4136 - val_accuracy: 0.8250\n",
      "Epoch 10/100\n",
      "800/800 [==============================] - 0s 114us/sample - loss: 0.4078 - accuracy: 0.8300 - val_loss: 0.4267 - val_accuracy: 0.8100\n",
      "Epoch 11/100\n",
      "800/800 [==============================] - 0s 138us/sample - loss: 0.4023 - accuracy: 0.8100 - val_loss: 0.3890 - val_accuracy: 0.8200\n",
      "Epoch 12/100\n",
      "800/800 [==============================] - 0s 114us/sample - loss: 0.3696 - accuracy: 0.8350 - val_loss: 0.3700 - val_accuracy: 0.8500\n",
      "Epoch 13/100\n",
      "800/800 [==============================] - 0s 136us/sample - loss: 0.3584 - accuracy: 0.8413 - val_loss: 0.3534 - val_accuracy: 0.8500\n",
      "Epoch 14/100\n",
      "800/800 [==============================] - 0s 118us/sample - loss: 0.3468 - accuracy: 0.8550 - val_loss: 0.3594 - val_accuracy: 0.8800\n",
      "Epoch 15/100\n",
      "800/800 [==============================] - 0s 119us/sample - loss: 0.3398 - accuracy: 0.8425 - val_loss: 0.3668 - val_accuracy: 0.8300\n",
      "Epoch 16/100\n",
      "800/800 [==============================] - 0s 135us/sample - loss: 0.3187 - accuracy: 0.8600 - val_loss: 0.3288 - val_accuracy: 0.8400\n",
      "Epoch 17/100\n",
      "800/800 [==============================] - 0s 146us/sample - loss: 0.3077 - accuracy: 0.8600 - val_loss: 0.3179 - val_accuracy: 0.8650\n",
      "Epoch 18/100\n",
      "800/800 [==============================] - 0s 137us/sample - loss: 0.3154 - accuracy: 0.8700 - val_loss: 0.3208 - val_accuracy: 0.8600\n",
      "Epoch 19/100\n",
      "800/800 [==============================] - 0s 123us/sample - loss: 0.3117 - accuracy: 0.8625 - val_loss: 0.3025 - val_accuracy: 0.8550\n",
      "Epoch 20/100\n",
      "800/800 [==============================] - 0s 121us/sample - loss: 0.2798 - accuracy: 0.8825 - val_loss: 0.3090 - val_accuracy: 0.8600\n",
      "Epoch 21/100\n",
      "800/800 [==============================] - 0s 148us/sample - loss: 0.2822 - accuracy: 0.8725 - val_loss: 0.2854 - val_accuracy: 0.8800\n",
      "Epoch 22/100\n",
      "800/800 [==============================] - 0s 122us/sample - loss: 0.2722 - accuracy: 0.8925 - val_loss: 0.2817 - val_accuracy: 0.8700\n",
      "Epoch 23/100\n",
      "800/800 [==============================] - 0s 139us/sample - loss: 0.2852 - accuracy: 0.8788 - val_loss: 0.2978 - val_accuracy: 0.9050\n",
      "Epoch 24/100\n",
      "800/800 [==============================] - 0s 135us/sample - loss: 0.2815 - accuracy: 0.8650 - val_loss: 0.3232 - val_accuracy: 0.8500\n",
      "Epoch 25/100\n",
      "800/800 [==============================] - 0s 117us/sample - loss: 0.2715 - accuracy: 0.8838 - val_loss: 0.2741 - val_accuracy: 0.8700\n",
      "Epoch 26/100\n",
      "800/800 [==============================] - 0s 133us/sample - loss: 0.2442 - accuracy: 0.9050 - val_loss: 0.2839 - val_accuracy: 0.8650\n",
      "Epoch 27/100\n",
      "800/800 [==============================] - 0s 148us/sample - loss: 0.2424 - accuracy: 0.8988 - val_loss: 0.2601 - val_accuracy: 0.9000\n",
      "Epoch 28/100\n",
      "800/800 [==============================] - 0s 190us/sample - loss: 0.2343 - accuracy: 0.9112 - val_loss: 0.2752 - val_accuracy: 0.8650\n",
      "Epoch 29/100\n",
      "800/800 [==============================] - 0s 222us/sample - loss: 0.2287 - accuracy: 0.9100 - val_loss: 0.2529 - val_accuracy: 0.8750\n",
      "Epoch 30/100\n",
      "800/800 [==============================] - 0s 119us/sample - loss: 0.2234 - accuracy: 0.9150 - val_loss: 0.2608 - val_accuracy: 0.8750\n",
      "Epoch 31/100\n",
      "800/800 [==============================] - 0s 127us/sample - loss: 0.2303 - accuracy: 0.9013 - val_loss: 0.3624 - val_accuracy: 0.8550\n",
      "Epoch 32/100\n",
      "800/800 [==============================] - 0s 137us/sample - loss: 0.2482 - accuracy: 0.8900 - val_loss: 0.2626 - val_accuracy: 0.8800\n",
      "Epoch 33/100\n",
      "800/800 [==============================] - 0s 133us/sample - loss: 0.2517 - accuracy: 0.8988 - val_loss: 0.2977 - val_accuracy: 0.8700\n",
      "Epoch 34/100\n",
      "800/800 [==============================] - 0s 146us/sample - loss: 0.2852 - accuracy: 0.8662 - val_loss: 0.2459 - val_accuracy: 0.9100\n",
      "Epoch 35/100\n",
      "800/800 [==============================] - 0s 139us/sample - loss: 0.2275 - accuracy: 0.9050 - val_loss: 0.3593 - val_accuracy: 0.8450\n",
      "Epoch 36/100\n",
      "800/800 [==============================] - 0s 144us/sample - loss: 0.2545 - accuracy: 0.8875 - val_loss: 0.2966 - val_accuracy: 0.8650\n",
      "Epoch 37/100\n",
      "800/800 [==============================] - 0s 135us/sample - loss: 0.2289 - accuracy: 0.9062 - val_loss: 0.2585 - val_accuracy: 0.8700\n",
      "Epoch 38/100\n",
      "800/800 [==============================] - 0s 144us/sample - loss: 0.2060 - accuracy: 0.9125 - val_loss: 0.2211 - val_accuracy: 0.9350\n",
      "Epoch 39/100\n",
      "800/800 [==============================] - 0s 172us/sample - loss: 0.2057 - accuracy: 0.9137 - val_loss: 0.2244 - val_accuracy: 0.9200\n",
      "Epoch 40/100\n",
      "800/800 [==============================] - 0s 155us/sample - loss: 0.1901 - accuracy: 0.9237 - val_loss: 0.2480 - val_accuracy: 0.8750\n",
      "Epoch 41/100\n",
      "800/800 [==============================] - 0s 142us/sample - loss: 0.1862 - accuracy: 0.9300 - val_loss: 0.2302 - val_accuracy: 0.8900\n",
      "Epoch 42/100\n",
      "800/800 [==============================] - 0s 144us/sample - loss: 0.1946 - accuracy: 0.9212 - val_loss: 0.2920 - val_accuracy: 0.8750\n",
      "Epoch 43/100\n",
      "800/800 [==============================] - 0s 155us/sample - loss: 0.2378 - accuracy: 0.8825 - val_loss: 0.2136 - val_accuracy: 0.9050\n",
      "Epoch 44/100\n",
      "800/800 [==============================] - 0s 179us/sample - loss: 0.1804 - accuracy: 0.9200 - val_loss: 0.2272 - val_accuracy: 0.8950\n",
      "Epoch 45/100\n",
      "800/800 [==============================] - 0s 158us/sample - loss: 0.1667 - accuracy: 0.9413 - val_loss: 0.2087 - val_accuracy: 0.9100\n",
      "Epoch 46/100\n",
      "800/800 [==============================] - 0s 115us/sample - loss: 0.1617 - accuracy: 0.9450 - val_loss: 0.2556 - val_accuracy: 0.8750\n",
      "Epoch 47/100\n",
      "800/800 [==============================] - 0s 127us/sample - loss: 0.1670 - accuracy: 0.9475 - val_loss: 0.1957 - val_accuracy: 0.9350\n",
      "Epoch 48/100\n",
      "800/800 [==============================] - 0s 146us/sample - loss: 0.1540 - accuracy: 0.9500 - val_loss: 0.1983 - val_accuracy: 0.9150\n",
      "Epoch 49/100\n",
      "800/800 [==============================] - 0s 190us/sample - loss: 0.1598 - accuracy: 0.9488 - val_loss: 0.1879 - val_accuracy: 0.9250\n",
      "Epoch 50/100\n",
      "800/800 [==============================] - 0s 153us/sample - loss: 0.1500 - accuracy: 0.9538 - val_loss: 0.1911 - val_accuracy: 0.9250\n",
      "Epoch 51/100\n",
      "800/800 [==============================] - 0s 172us/sample - loss: 0.1422 - accuracy: 0.9550 - val_loss: 0.1833 - val_accuracy: 0.9300\n",
      "Epoch 52/100\n",
      "800/800 [==============================] - 0s 162us/sample - loss: 0.1767 - accuracy: 0.9262 - val_loss: 0.2513 - val_accuracy: 0.8850\n",
      "Epoch 53/100\n",
      "800/800 [==============================] - 0s 177us/sample - loss: 0.1785 - accuracy: 0.9275 - val_loss: 0.1921 - val_accuracy: 0.9300\n",
      "Epoch 54/100\n",
      "800/800 [==============================] - 0s 193us/sample - loss: 0.1630 - accuracy: 0.9350 - val_loss: 0.2375 - val_accuracy: 0.8750\n",
      "Epoch 55/100\n",
      "800/800 [==============================] - 0s 169us/sample - loss: 0.1586 - accuracy: 0.9300 - val_loss: 0.1826 - val_accuracy: 0.9350\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 205us/sample - loss: 0.1698 - accuracy: 0.9312 - val_loss: 0.1970 - val_accuracy: 0.9300\n",
      "Epoch 57/100\n",
      "800/800 [==============================] - 0s 170us/sample - loss: 0.1634 - accuracy: 0.9337 - val_loss: 0.2497 - val_accuracy: 0.8750\n",
      "Epoch 58/100\n",
      "800/800 [==============================] - 0s 236us/sample - loss: 0.1688 - accuracy: 0.9413 - val_loss: 0.1864 - val_accuracy: 0.9250\n",
      "Epoch 59/100\n",
      "800/800 [==============================] - 0s 230us/sample - loss: 0.1829 - accuracy: 0.9237 - val_loss: 0.2278 - val_accuracy: 0.9200\n",
      "Epoch 60/100\n",
      "800/800 [==============================] - 0s 221us/sample - loss: 0.1521 - accuracy: 0.9350 - val_loss: 0.1719 - val_accuracy: 0.9400\n",
      "Epoch 61/100\n",
      "800/800 [==============================] - 0s 186us/sample - loss: 0.1242 - accuracy: 0.9650 - val_loss: 0.1598 - val_accuracy: 0.9400\n",
      "Epoch 62/100\n",
      "800/800 [==============================] - 0s 167us/sample - loss: 0.1231 - accuracy: 0.9613 - val_loss: 0.1776 - val_accuracy: 0.9050\n",
      "Epoch 63/100\n",
      "800/800 [==============================] - 0s 165us/sample - loss: 0.1164 - accuracy: 0.9712 - val_loss: 0.1553 - val_accuracy: 0.9450\n",
      "Epoch 64/100\n",
      "800/800 [==============================] - 0s 122us/sample - loss: 0.1151 - accuracy: 0.9712 - val_loss: 0.1563 - val_accuracy: 0.9450\n",
      "Epoch 65/100\n",
      "800/800 [==============================] - 0s 168us/sample - loss: 0.1090 - accuracy: 0.9750 - val_loss: 0.1919 - val_accuracy: 0.8900\n",
      "Epoch 66/100\n",
      "800/800 [==============================] - 0s 132us/sample - loss: 0.1154 - accuracy: 0.9725 - val_loss: 0.1479 - val_accuracy: 0.9500\n",
      "Epoch 67/100\n",
      "800/800 [==============================] - 0s 156us/sample - loss: 0.1159 - accuracy: 0.9650 - val_loss: 0.1440 - val_accuracy: 0.9450\n",
      "Epoch 68/100\n",
      "800/800 [==============================] - 0s 126us/sample - loss: 0.1448 - accuracy: 0.9413 - val_loss: 0.1735 - val_accuracy: 0.9300\n",
      "Epoch 69/100\n",
      "800/800 [==============================] - 0s 143us/sample - loss: 0.1094 - accuracy: 0.9675 - val_loss: 0.1428 - val_accuracy: 0.9550\n",
      "Epoch 70/100\n",
      "800/800 [==============================] - 0s 136us/sample - loss: 0.1066 - accuracy: 0.9762 - val_loss: 0.1413 - val_accuracy: 0.9500\n",
      "Epoch 71/100\n",
      "800/800 [==============================] - 0s 160us/sample - loss: 0.1065 - accuracy: 0.9725 - val_loss: 0.1512 - val_accuracy: 0.9350\n",
      "Epoch 72/100\n",
      "800/800 [==============================] - 0s 139us/sample - loss: 0.0983 - accuracy: 0.9762 - val_loss: 0.1407 - val_accuracy: 0.9450\n",
      "Epoch 73/100\n",
      "800/800 [==============================] - 0s 116us/sample - loss: 0.0964 - accuracy: 0.9862 - val_loss: 0.1351 - val_accuracy: 0.9400\n",
      "Epoch 74/100\n",
      "800/800 [==============================] - 0s 115us/sample - loss: 0.0978 - accuracy: 0.9800 - val_loss: 0.1338 - val_accuracy: 0.9550\n",
      "Epoch 75/100\n",
      "800/800 [==============================] - 0s 105us/sample - loss: 0.0907 - accuracy: 0.9862 - val_loss: 0.1251 - val_accuracy: 0.9600\n",
      "Epoch 76/100\n",
      "800/800 [==============================] - 0s 140us/sample - loss: 0.0984 - accuracy: 0.9725 - val_loss: 0.1357 - val_accuracy: 0.9450\n",
      "Epoch 77/100\n",
      "800/800 [==============================] - 0s 131us/sample - loss: 0.0994 - accuracy: 0.9712 - val_loss: 0.1227 - val_accuracy: 0.9600\n",
      "Epoch 78/100\n",
      "800/800 [==============================] - 0s 151us/sample - loss: 0.0934 - accuracy: 0.9787 - val_loss: 0.2280 - val_accuracy: 0.8700\n",
      "Epoch 79/100\n",
      "800/800 [==============================] - 0s 147us/sample - loss: 0.0984 - accuracy: 0.9725 - val_loss: 0.1218 - val_accuracy: 0.9550\n",
      "Epoch 80/100\n",
      "800/800 [==============================] - 0s 182us/sample - loss: 0.0923 - accuracy: 0.9800 - val_loss: 0.1886 - val_accuracy: 0.8950\n",
      "Epoch 81/100\n",
      "800/800 [==============================] - 0s 131us/sample - loss: 0.0891 - accuracy: 0.9800 - val_loss: 0.1199 - val_accuracy: 0.9550\n",
      "Epoch 82/100\n",
      "800/800 [==============================] - 0s 120us/sample - loss: 0.0771 - accuracy: 0.9887 - val_loss: 0.1363 - val_accuracy: 0.9350\n",
      "Epoch 83/100\n",
      "800/800 [==============================] - 0s 120us/sample - loss: 0.0849 - accuracy: 0.9787 - val_loss: 0.1191 - val_accuracy: 0.9500\n",
      "Epoch 84/100\n",
      "800/800 [==============================] - 0s 112us/sample - loss: 0.1081 - accuracy: 0.9600 - val_loss: 0.1850 - val_accuracy: 0.8950\n",
      "Epoch 85/100\n",
      "800/800 [==============================] - 0s 144us/sample - loss: 0.1056 - accuracy: 0.9575 - val_loss: 0.1146 - val_accuracy: 0.9600\n",
      "Epoch 86/100\n",
      "800/800 [==============================] - 0s 147us/sample - loss: 0.0832 - accuracy: 0.9812 - val_loss: 0.1111 - val_accuracy: 0.9550\n",
      "Epoch 87/100\n",
      "800/800 [==============================] - 0s 165us/sample - loss: 0.0713 - accuracy: 0.9900 - val_loss: 0.1311 - val_accuracy: 0.9500\n",
      "Epoch 88/100\n",
      "800/800 [==============================] - 0s 146us/sample - loss: 0.0704 - accuracy: 0.9900 - val_loss: 0.1004 - val_accuracy: 0.9550\n",
      "Epoch 89/100\n",
      "800/800 [==============================] - 0s 137us/sample - loss: 0.0642 - accuracy: 0.9925 - val_loss: 0.0973 - val_accuracy: 0.9650\n",
      "Epoch 90/100\n",
      "800/800 [==============================] - 0s 142us/sample - loss: 0.0658 - accuracy: 0.9912 - val_loss: 0.1316 - val_accuracy: 0.9400\n",
      "Epoch 91/100\n",
      "800/800 [==============================] - 0s 149us/sample - loss: 0.0696 - accuracy: 0.9912 - val_loss: 0.1049 - val_accuracy: 0.9550\n",
      "Epoch 92/100\n",
      "800/800 [==============================] - 0s 137us/sample - loss: 0.0786 - accuracy: 0.9825 - val_loss: 0.1741 - val_accuracy: 0.9050\n",
      "Epoch 93/100\n",
      "800/800 [==============================] - 0s 115us/sample - loss: 0.0822 - accuracy: 0.9762 - val_loss: 0.1110 - val_accuracy: 0.9450\n",
      "Epoch 94/100\n",
      "800/800 [==============================] - 0s 139us/sample - loss: 0.0684 - accuracy: 0.9925 - val_loss: 0.0905 - val_accuracy: 0.9650\n",
      "Epoch 95/100\n",
      "800/800 [==============================] - 0s 140us/sample - loss: 0.0864 - accuracy: 0.9725 - val_loss: 0.1009 - val_accuracy: 0.9650\n",
      "Epoch 96/100\n",
      "800/800 [==============================] - 0s 124us/sample - loss: 0.1180 - accuracy: 0.9475 - val_loss: 0.1053 - val_accuracy: 0.9650\n",
      "Epoch 97/100\n",
      "800/800 [==============================] - 0s 180us/sample - loss: 0.0954 - accuracy: 0.9588 - val_loss: 0.2645 - val_accuracy: 0.8900\n",
      "Epoch 98/100\n",
      "800/800 [==============================] - 0s 194us/sample - loss: 0.1112 - accuracy: 0.9588 - val_loss: 0.1005 - val_accuracy: 0.9600\n",
      "Epoch 99/100\n",
      "800/800 [==============================] - 0s 170us/sample - loss: 0.0710 - accuracy: 0.9800 - val_loss: 0.0854 - val_accuracy: 0.9650\n",
      "Epoch 100/100\n",
      "800/800 [==============================] - 0s 185us/sample - loss: 0.0538 - accuracy: 0.9975 - val_loss: 0.0805 - val_accuracy: 0.9800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb16365ea50>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "#Setup hyperparameters for deep learning\n",
    "EPOCHS=100\n",
    "BATCH_SIZE=100\n",
    "VERBOSE=1\n",
    "NB_CLASSES=2\n",
    "N_HIDDEN=128\n",
    "VALIDATION_SPLIT=0.2\n",
    "\n",
    "#Create a Keras model\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "#Add first hidden Dense layer\n",
    "model.add(keras.layers.Dense(N_HIDDEN,\n",
    "                             input_shape=(6,),\n",
    "                              name='Dense-Layer-1',\n",
    "                              activation='relu'))\n",
    "\n",
    "#Add a second hidden dense layer\n",
    "model.add(keras.layers.Dense(N_HIDDEN,\n",
    "                              name='Dense-Layer-2',\n",
    "                              activation='relu'))\n",
    "\n",
    "#Add a final layer with softmax\n",
    "model.add(keras.layers.Dense(NB_CLASSES,\n",
    "                             name='Final',\n",
    "                             activation='softmax'))\n",
    "\n",
    "#Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#Fit parameters \n",
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=BATCH_SIZE,\n",
    "          epochs=EPOCHS,\n",
    "          verbose=VERBOSE,\n",
    "          validation_split=VALIDATION_SPLIT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02.06. Predict Attrition with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will employee leave ? [1]\n"
     ]
    }
   ],
   "source": [
    "TotalMonthsOfExp=40\n",
    "TotalOrgsWorked=4\n",
    "MonthsInOrg=20\n",
    "LastPayIncrementBand=5\n",
    "AverageFeedback=4\n",
    "LastPromotionYears=4\n",
    "\n",
    "print(\"Will employee leave ?\", model.predict_classes([[TotalMonthsOfExp,\n",
    "                                  TotalOrgsWorked,\n",
    "                                  MonthsInOrg,\n",
    "                                  LastPayIncrementBand,\n",
    "                                  AverageFeedback,\n",
    "                                  LastPromotionYears]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0 0 0 1 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "#Bulk predictions\n",
    "\n",
    "print(model.predict_classes(\n",
    "    [[111,5,85,3,2,2],\n",
    "    [31,2,15,4,1,4],\n",
    "    [61,4,24,1,4,3],\n",
    "    [77,4,35,3,1,1],\n",
    "    [81,5,7,1,2,3],\n",
    "    [113,4,112,5,4,1],\n",
    "    [101,2,48,5,1,4],\n",
    "    [45,4,22,5,3,1],\n",
    "    [25,2,2,2,3,2],\n",
    "    [97,3,15,3,2,4]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
